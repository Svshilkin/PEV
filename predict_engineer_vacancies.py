import os
import argparse
import warnings
warnings.filterwarnings('ignore')

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º —Ñ—É–Ω–∫—Ü–∏–∏ –∏–∑ –Ω–∞—à–∏—Ö –º–æ–¥—É–ª–µ–π
from prepare_data_script import prepare_vacancies_data
from solution import main as run_forecasting

def parse_arguments():
    """–ü–∞—Ä—Å–∏–Ω–≥ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤ –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏"""
    parser = argparse.ArgumentParser(description='–ü—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ—Ç—Ä–µ–±–Ω–æ—Å—Ç–∏ –≤ –∏–Ω–∂–µ–Ω–µ—Ä–Ω—ã—Ö –∫–∞–¥—Ä–∞—Ö')
    
    parser.add_argument('--input', type=str, default='vacancies.csv',
                        help='–ü—É—Ç—å –∫ –≤—Ö–æ–¥–Ω–æ–º—É CSV-—Ñ–∞–π–ª—É —Å –≤–∞–∫–∞–Ω—Å–∏—è–º–∏')
    
    parser.add_argument('--output-dir', type=str, default='results',
                        help='–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤')
    
    parser.add_argument('--skip-prepare', action='store_true',
                        help='–ü—Ä–æ–ø—É—Å—Ç–∏—Ç—å —ç—Ç–∞–ø –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –¥–∞–Ω–Ω—ã—Ö')
    
    parser.add_argument('--processed-data', type=str, default=None,
                        help='–ü—É—Ç—å –∫ —É–∂–µ –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–Ω—ã–º –¥–∞–Ω–Ω—ã–º (–¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —Å --skip-prepare)')

    parser.add_argument('--is-raw', action='store_true',
                        help='–ò—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –ª–∏ —Å—ã—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ')
    
    parser.add_argument('--forecast-periods', type=int, default=6,
                        help='–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–µ—Ä–∏–æ–¥–æ–≤ –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è')
    
    parser.add_argument('--validation-periods', type=int, default=6,
                        help='–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–µ—Ä–∏–æ–¥–æ–≤ –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏')
    
    parser.add_argument('--auto-anomaly-detection', action='store_true', default=True,
                        help='–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –∏ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –∞–Ω–æ–º–∞–ª–∏–π (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –≤–∫–ª—é—á–µ–Ω–æ)')
    
    parser.add_argument('--anomaly-threshold', type=float, default=3.0,
                        help='–ü–æ—Ä–æ–≥ –¥–ª—è –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –∞–Ω–æ–º–∞–ª–∏–π (Z-score)')
    
    parser.add_argument('--auto-config', action='store_true',
                        help='–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –≤—ã–±–æ—Ä –ª—É—á—à–µ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏')
    
    return parser.parse_args()

def run_pipeline():
    """–ó–∞–ø—É—Å–∫ –ø–æ–ª–Ω–æ–≥–æ –ø–∞–π–ø–ª–∞–π–Ω–∞ –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è"""
    print("üöÄ –°–ò–°–¢–ï–ú–ê –ü–†–û–ì–ù–û–ó–ò–†–û–í–ê–ù–ò–Ø –ò–ù–ñ–ï–ù–ï–†–ù–´–• –ö–ê–î–†–û–í")
    print("="*70)
    
    # –ü–æ–ª—É—á–∞–µ–º –∞—Ä–≥—É–º–µ–Ω—Ç—ã
    args = parse_arguments()
    
    # –°–æ–∑–¥–∞–µ–º –≤—ã—Ö–æ–¥–Ω—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é, –µ—Å–ª–∏ –æ–Ω–∞ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
    os.makedirs(args.output_dir, exist_ok=True)
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø—É—Ç–∏ –∫ —Ñ–∞–π–ª–∞–º
    input_file = args.input
    processed_file = args.processed_data if args.processed_data else os.path.join(args.output_dir, 'processed_vacancies.csv')
    
    # –®–∞–≥ 1: –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    if not args.skip_prepare:
        print("\n" + "=" * 80)
        print("–≠–¢–ê–ü 1: –ü–û–î–ì–û–¢–û–í–ö–ê –î–ê–ù–ù–´–•")
        print("=" * 80)
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º –ø–æ–¥–≥–æ—Ç–æ–≤–∫—É –¥–∞–Ω–Ω—ã—Ö
        processed_df = prepare_vacancies_data(
            raw=args.is_raw,
            input_file=input_file,
            output_file=processed_file,
            visualize=True
        )
        
        if processed_df is None:
            print("\n–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–µ –¥–∞–Ω–Ω—ã—Ö. –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ —Ä–∞–±–æ—Ç—ã.")
            return
    else:
        print("\n–ü—Ä–æ–ø—É—Å–∫–∞–µ–º —ç—Ç–∞–ø –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –¥–∞–Ω–Ω—ã—Ö, –∏—Å–ø–æ–ª—å–∑—É—è —É–∂–µ –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ.")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ª–∏ —Ñ–∞–π–ª —Å –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏
        if not os.path.exists(processed_file):
            print(f"–û—à–∏–±–∫–∞: —Ñ–∞–π–ª —Å –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω: {processed_file}")
            print("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —É–∫–∞–∂–∏—Ç–µ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –ø—É—Ç—å –∏–ª–∏ —É–±–µ—Ä–∏—Ç–µ —Ñ–ª–∞–≥ --skip-prepare")
            return
    
    # –®–∞–≥ 2: –ó–∞–ø—É—Å–∫ –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è
    print("\n" + "=" * 80)
    print("–≠–¢–ê–ü 2: –ü–†–û–ì–ù–û–ó–ò–†–û–í–ê–ù–ò–ï")
    print("=" * 80)
    
    # –ü–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª—è–µ–º –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –≥–ª–æ–±–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è
    import solution
    solution.file_path = processed_file
    solution.output_folder = args.output_dir
    solution.forecast_periods = args.forecast_periods
    solution.validation_periods = args.validation_periods
    
    # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞—Ö
    if args.auto_config:
        print("üîß –í–∫–ª—é—á–µ–Ω —Ä–µ–∂–∏–º –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –≤—ã–±–æ—Ä–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏")
        print("   –°–∏—Å—Ç–µ–º–∞ –ø—Ä–æ—Ç–µ—Å—Ç–∏—Ä—É–µ—Ç —Ä–∞–∑–ª–∏—á–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∏ –≤—ã–±–µ—Ä–µ—Ç –ª—É—á—à–∏–µ")
    
    print(f"üìä –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è:")
    print(f"   ‚Ä¢ –ì–æ—Ä–∏–∑–æ–Ω—Ç –ø—Ä–æ–≥–Ω–æ–∑–∞: {args.forecast_periods} –ø–µ—Ä–∏–æ–¥–æ–≤")
    print(f"   ‚Ä¢ –í–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã–π –ø–µ—Ä–∏–æ–¥: {args.validation_periods} –ø–µ—Ä–∏–æ–¥–æ–≤")
    print(f"   ‚Ä¢ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –∞–Ω–æ–º–∞–ª–∏–π: {'–î–∞' if args.auto_anomaly_detection else '–ù–µ—Ç'}")
    if args.auto_anomaly_detection:
        print(f"   ‚Ä¢ –ü–æ—Ä–æ–≥ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –∞–Ω–æ–º–∞–ª–∏–π: {args.anomaly_threshold}")
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ
    try:
        run_forecasting()
        
        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        print("\n" + "=" * 80)
        print("–≠–¢–ê–ü 3: –ê–ù–ê–õ–ò–ó –†–ï–ó–£–õ–¨–¢–ê–¢–û–í")
        print("=" * 80)
        
        analyze_results(args.output_dir)
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–∏: {e}")
        import traceback
        traceback.print_exc()
        return
    
    print("\n" + "=" * 80)
    print("–ó–ê–í–ï–†–®–ï–ù–ò–ï –†–ê–ë–û–¢–´")
    print("=" * 80)
    print(f"‚úÖ –í—Å–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏: {args.output_dir}")
    print("\nüìÇ –°–æ–∑–¥–∞–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã:")
    
    # –í—ã–≤–æ–¥–∏–º —Å–ø–∏—Å–æ–∫ —Å–æ–∑–¥–∞–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
    output_files = [
        "demand_before_anomaly_fix.png",
        "anomaly_before_fix.png", 
        "anomaly_after_fix.png",
        "total_demand.png",
        "seasonal_decomposition.png",
        "monthly_seasonality.png",
        "top_industries.png",
        "industry_demand_forecast.csv",
        "random_forest_metrics.csv",
        "gradient_boosting_metrics.csv",
        "best_models_per_industry.csv",
        "model_comparison.png",
        "final_report.txt"
    ]
    
    for file_name in output_files:
        file_path = os.path.join(args.output_dir, file_name)
        if os.path.exists(file_path):
            file_size = os.path.getsize(file_path)
            print(f"   ‚úì {file_name} ({file_size:,} –±–∞–π—Ç)")
        else:
            print(f"   ‚ö† {file_name} (–Ω–µ —Å–æ–∑–¥–∞–Ω)")
    
    print(f"\nüéØ –û—Å–Ω–æ–≤–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã:")
    try:
        # –ß–∏—Ç–∞–µ–º –∏ –≤—ã–≤–æ–¥–∏–º –∫–ª—é—á–µ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –∏–∑ –æ—Ç—á–µ—Ç–∞
        report_path = os.path.join(args.output_dir, 'final_report.txt')
        if os.path.exists(report_path):
            with open(report_path, 'r', encoding='utf-8') as f:
                report_content = f.read()
                # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–ª—é—á–µ–≤—ã–µ —Å—Ç—Ä–æ–∫–∏
                lines = report_content.split('\n')
                for line in lines:
                    if '–õ—É—á—à–∏–π R¬≤:' in line or '–õ—É—á—à–∞—è –º–æ–¥–µ–ª—å –ø–æ —Å—Ä–µ–¥–Ω–µ–º—É RMSE:' in line or '–õ—É—á—à–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è:' in line:
                        print(f"   {line.strip()}")
    except Exception as e:
        print(f"   –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å –æ—Ç—á–µ—Ç: {e}")

def analyze_results(output_dir):
    """–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"""
    print("üìà –ü—Ä–æ–≤–µ–¥–µ–Ω–∏–µ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤...")
    
    try:
        import pandas as pd
        import matplotlib.pyplot as plt
        
        # –ê–Ω–∞–ª–∏–∑ –º–µ—Ç—Ä–∏–∫
        rf_metrics_path = os.path.join(output_dir, 'random_forest_metrics.csv')
        gb_metrics_path = os.path.join(output_dir, 'gradient_boosting_metrics.csv')
        
        if os.path.exists(rf_metrics_path) and os.path.exists(gb_metrics_path):
            rf_metrics = pd.read_csv(rf_metrics_path, index_col=0)
            gb_metrics = pd.read_csv(gb_metrics_path, index_col=0)
            
            print("üìä –°–≤–æ–¥–∫–∞ –º–µ—Ç—Ä–∏–∫ –∫–∞—á–µ—Å—Ç–≤–∞:")
            print(f"   Random Forest - —Å—Ä–µ–¥–Ω–∏–π R¬≤: {rf_metrics['R2'].mean():.4f}")
            print(f"   XGBoost - —Å—Ä–µ–¥–Ω–∏–π R¬≤: {gb_metrics['R2'].mean():.4f}")
            print(f"   Random Forest - —Å—Ä–µ–¥–Ω–∏–π RMSE: {rf_metrics['RMSE'].mean():.2f}")
            print(f"   XGBoost - —Å—Ä–µ–¥–Ω–∏–π RMSE: {gb_metrics['RMSE'].mean():.2f}")
            
            # –°–æ–∑–¥–∞–Ω–∏–µ –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
            plt.figure(figsize=(15, 5))
            
            # Subplot 1: R¬≤ –ø–æ –æ—Ç—Ä–∞—Å–ª—è–º
            plt.subplot(1, 3, 1)
            industries = rf_metrics.index
            x_pos = range(len(industries))
            
            plt.bar([x - 0.2 for x in x_pos], rf_metrics['R2'], 0.4, label='Random Forest', alpha=0.7)
            plt.bar([x + 0.2 for x in x_pos], gb_metrics['R2'], 0.4, label='XGBoost', alpha=0.7)
            
            plt.xlabel('–û—Ç—Ä–∞—Å–ª–∏')
            plt.ylabel('R¬≤')
            plt.title('R¬≤ –ø–æ –æ—Ç—Ä–∞—Å–ª—è–º')
            plt.xticks(x_pos, industries, rotation=45, ha='right')
            plt.legend()
            plt.grid(True, alpha=0.3)
            
            # Subplot 2: RMSE –ø–æ –æ—Ç—Ä–∞—Å–ª—è–º
            plt.subplot(1, 3, 2)
            plt.bar([x - 0.2 for x in x_pos], rf_metrics['RMSE'], 0.4, label='Random Forest', alpha=0.7)
            plt.bar([x + 0.2 for x in x_pos], gb_metrics['RMSE'], 0.4, label='XGBoost', alpha=0.7)
            
            plt.xlabel('–û—Ç—Ä–∞—Å–ª–∏')
            plt.ylabel('RMSE')
            plt.title('RMSE –ø–æ –æ—Ç—Ä–∞—Å–ª—è–º')
            plt.xticks(x_pos, industries, rotation=45, ha='right')
            plt.legend()
            plt.grid(True, alpha=0.3)
            
            # Subplot 3: MAE –ø–æ –æ—Ç—Ä–∞—Å–ª—è–º
            plt.subplot(1, 3, 3)
            plt.bar([x - 0.2 for x in x_pos], rf_metrics['MAE'], 0.4, label='Random Forest', alpha=0.7)
            plt.bar([x + 0.2 for x in x_pos], gb_metrics['MAE'], 0.4, label='XGBoost', alpha=0.7)
            
            plt.xlabel('–û—Ç—Ä–∞—Å–ª–∏')
            plt.ylabel('MAE')
            plt.title('MAE –ø–æ –æ—Ç—Ä–∞—Å–ª—è–º')
            plt.xticks(x_pos, industries, rotation=45, ha='right')
            plt.legend()
            plt.grid(True, alpha=0.3)
            
            plt.tight_layout()
            plt.savefig(os.path.join(output_dir, 'detailed_metrics_comparison.png'), dpi=300, bbox_inches='tight')
            plt.close()
            
            print("   ‚úì –°–æ–∑–¥–∞–Ω –¥–µ—Ç–∞–ª—å–Ω—ã–π –≥—Ä–∞—Ñ–∏–∫ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –º–µ—Ç—Ä–∏–∫")
        
        # –ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–≥–Ω–æ–∑–æ–≤
        forecast_path = os.path.join(output_dir, 'industry_demand_forecast.csv')
        if os.path.exists(forecast_path):
            forecast_df = pd.read_csv(forecast_path, index_col=0)
            forecast_df.index = pd.to_datetime(forecast_df.index)
            
            print(f"üìÖ –ü—Ä–æ–≥–Ω–æ–∑—ã —Å–æ–∑–¥–∞–Ω—ã –¥–ª—è {len(forecast_df.columns)} –ø–æ–∫–∞–∑–∞—Ç–µ–ª–µ–π")
            print(f"   –ì–æ—Ä–∏–∑–æ–Ω—Ç –ø—Ä–æ–≥–Ω–æ–∑–∞: {forecast_df.index[0].strftime('%Y-%m')} - {forecast_df.index[-1].strftime('%Y-%m')}")
            
            if 'total_demand' in forecast_df.columns:
                total_forecast = forecast_df['total_demand']
                print(f"   –ü—Ä–æ–≥–Ω–æ–∑ –æ–±—â–µ–≥–æ —Å–ø—Ä–æ—Å–∞: {total_forecast.iloc[0]:,.0f} - {total_forecast.iloc[-1]:,.0f} —Ä–∞–±–æ—á–∏—Ö –º–µ—Å—Ç")
                print(f"   –°—Ä–µ–¥–Ω–∏–π –º–µ—Å—è—á–Ω—ã–π —Å–ø—Ä–æ—Å: {total_forecast.mean():,.0f} —Ä–∞–±–æ—á–∏—Ö –º–µ—Å—Ç")
            
            # –°–æ–∑–¥–∞–Ω–∏–µ —Å–≤–æ–¥–Ω–æ–≥–æ –≥—Ä–∞—Ñ–∏–∫–∞ –ø—Ä–æ–≥–Ω–æ–∑–æ–≤
            plt.figure(figsize=(15, 8))
            
            # –°—Ç—Ä–æ–∏–º –ø—Ä–æ–≥–Ω–æ–∑—ã –¥–ª—è –≤—Å–µ—Ö –æ—Ç—Ä–∞—Å–ª–µ–π
            for col in forecast_df.columns:
                if col != 'total_demand':
                    plt.plot(forecast_df.index, forecast_df[col], label=col, alpha=0.7)
                else:
                    plt.plot(forecast_df.index, forecast_df[col], label=col, linewidth=3, color='black')
            
            plt.title('–ü—Ä–æ–≥–Ω–æ–∑—ã –ø–æ—Ç—Ä–µ–±–Ω–æ—Å—Ç–∏ –≤ –∏–Ω–∂–µ–Ω–µ—Ä–Ω—ã—Ö –∫–∞–¥—Ä–∞—Ö –ø–æ –æ—Ç—Ä–∞—Å–ª—è–º')
            plt.xlabel('–ü–µ—Ä–∏–æ–¥')
            plt.ylabel('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–∞–±–æ—á–∏—Ö –º–µ—Å—Ç')
            plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
            plt.grid(True, alpha=0.3)
            plt.tight_layout()
            plt.savefig(os.path.join(output_dir, 'all_forecasts_summary.png'), dpi=300, bbox_inches='tight')
            plt.close()
            
            print("   ‚úì –°–æ–∑–¥–∞–Ω —Å–≤–æ–¥–Ω—ã–π –≥—Ä–∞—Ñ–∏–∫ –≤—Å–µ—Ö –ø—Ä–æ–≥–Ω–æ–∑–æ–≤")
        
    except Exception as e:
        print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–º –∞–Ω–∞–ª–∏–∑–µ: {e}")

if __name__ == "__main__":
    run_pipeline()
